{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "import wave\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_path = os.path.dirname(\n",
    "    \"/Users/khangnguyen/lab/bahnar_tts/\")\n",
    "# absolute_path = os.path.dirname(\n",
    "#     \"E:/SOFT/General_Subjects/artificial_intelligence/colab-tts-Bahnar/bahnar_tts/\")\n",
    "relative_path = \"pattern\"\n",
    "\n",
    "fullpath = os.path.join(absolute_path, relative_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, filename in enumerate(os.listdir(fullpath)):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distances(sound_file):\n",
    "    min_val = 10000\n",
    "\n",
    "    fs, data = read(sound_file)\n",
    "    data_size = len(data)\n",
    "\n",
    "    focus_size = int(0.15 * fs)\n",
    "\n",
    "    focuses = []\n",
    "    distances = []\n",
    "    idx = 0\n",
    "\n",
    "    while idx < len(data):\n",
    "        if data[idx] > min_val:\n",
    "            mean_idx = idx + focus_size // 2\n",
    "            focuses.append(float(mean_idx) / data_size)\n",
    "            if len(focuses) > 1:\n",
    "                last_focus = focuses[-2]\n",
    "                actual_focus = focuses[-1]\n",
    "                distances.append(actual_focus - last_focus)\n",
    "            idx += focus_size\n",
    "        else:\n",
    "            idx += 1\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_test(pattern, test, min_error):\n",
    "    if len(pattern) > len(test):\n",
    "        return False\n",
    "    for i, dt in enumerate(pattern):\n",
    "        if not dt - test[i] < min_error:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, filename in enumerate(os.listdir(fullpath)):\n",
    "    if filename == \"AnhSon\" or filename == \"ChiBi\":\n",
    "        subpath = os.path.join(fullpath, filename)\n",
    "        for c, f in enumerate(os.listdir(subpath)):\n",
    "            if f == \"conv-wav\":\n",
    "                subsubpath = os.path.join(subpath, f)\n",
    "                for c1, f1 in enumerate(os.listdir(subsubpath)):\n",
    "                    audiopath = os.path.join(subsubpath, f1)\n",
    "\n",
    "                    print(audiopath)\n",
    "                    raw = wave.open(audiopath)\n",
    "\n",
    "                    # reads all the frames\n",
    "                    # -1 indicates all or max frames\n",
    "                    signal = raw.readframes(-1)\n",
    "                    signal = np.frombuffer(signal, dtype=\"int16\")\n",
    "\n",
    "                    # gets the frame rate\n",
    "                    f_rate = raw.getframerate()\n",
    "\n",
    "                    time = np.linspace(\n",
    "                        0,  # start\n",
    "                        len(signal) / f_rate,\n",
    "                        num=len(signal)\n",
    "                    )\n",
    "                    print(len(signal))\n",
    "\n",
    "                    # using matplotlib to plot\n",
    "                    # creates a new figure\n",
    "                    plt.plot(time, signal, 'b')\n",
    "\n",
    "                    # load data\n",
    "                    r, d = wavfile.read(f\"{audiopath}\")\n",
    "                    # perform noise reduction\n",
    "                    reduced_noise = nr.reduce_noise(y=d, sr=r)\n",
    "                    wavfile.write(\n",
    "                        f\"{subpath}/reduce-noise/test{c1}.wav\", r, reduced_noise)\n",
    "\n",
    "                    # do a comparison of the reduced noise files\n",
    "                    adjusted_filepath = os.path.join(subpath, \"reduce-noise\")\n",
    "                    adjusted_filepath = os.path.join(\n",
    "                        adjusted_filepath, f\"test{c1}.wav\")\n",
    "\n",
    "                    raw = wave.open(adjusted_filepath)\n",
    "\n",
    "                    # reads all the frames\n",
    "                    # -1 indicates all or max frames\n",
    "                    signal = raw.readframes(-1)\n",
    "                    signal = np.frombuffer(signal, dtype=\"int16\")\n",
    "\n",
    "                    # gets the frame rate\n",
    "                    f_rate = raw.getframerate()\n",
    "\n",
    "\n",
    "                    # using matplotlib to plot\n",
    "                    # creates a new figure\n",
    "                    plt.plot(time, signal, 'r')\n",
    "\n",
    "                    # shows the plot\n",
    "                    # in new window\n",
    "                    plt.show()\n",
    "\n",
    "                    # title of the plot\n",
    "                    plt.title(\"Sound Wave\")\n",
    "\n",
    "                    # label of x-axis\n",
    "                    plt.xlabel(\"Time\")\n",
    "                    plt.ylabel(\"Soundwave\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, filename in enumerate(os.listdir(fullpath)):\n",
    "    if filename == \"AnhSon\":\n",
    "        subpath = os.path.join(fullpath, filename)\n",
    "        for c, f in enumerate(os.listdir(subpath)):\n",
    "            if f == \"reduce-noise\":\n",
    "                subsubpath = os.path.join(subpath, f)\n",
    "                for c1, f1 in enumerate(os.listdir(subsubpath)):\n",
    "                    if f1.endswith('wav'):\n",
    "                        audiopath = os.path.join(subsubpath, f1)\n",
    "                        print(audiopath)\n",
    "                        fs, data = read(audiopath)\n",
    "                        # we will use the size of the array\n",
    "                        # to determine the duration of the sound\n",
    "                        data_size = len(data)\n",
    "\n",
    "                        # build k-nearest neighbors\n",
    "                        # ...\n",
    "\n",
    "                        pattern = calc_distances(f1)\n",
    "                        test = calc_distances()  # filename to be processed #type: ignore\n",
    "\n",
    "                        min_error = 0.1\n",
    "\n",
    "                        print(accept_test(pattern, test, min_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = calc_distances(f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\")\n",
    "test = calc_distances(f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = f\"{absolute_path}/Ketquathuam/AnhSon/KH-CN/KH-CN03.wav\"\n",
    "input_data1 = f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\"\n",
    "# input_data = f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\"\n",
    "# input_data1 = f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\"\n",
    "\n",
    "raw = wave.open(input_data)\n",
    "raw1 = wave.open(input_data1)\n",
    "\n",
    "signal = raw.readframes(-1)\n",
    "signal = np.frombuffer(signal, dtype=\"int16\")\n",
    "signal1 = raw1.readframes(-1)\n",
    "signal1 = np.frombuffer(signal1, dtype=\"int16\")\n",
    "\n",
    "# gets the frame rate\n",
    "f_rate = raw.getframerate()\n",
    "f_rate1 = raw1.getframerate()\n",
    "\n",
    "time = np.linspace(\n",
    "    0,  # start\n",
    "    len(signal) / f_rate,\n",
    "    num=len(signal)\n",
    ")\n",
    "time1 = np.linspace(\n",
    "    0,  # start\n",
    "    len(signal1) / f_rate1,\n",
    "    num=len(signal1)\n",
    ")\n",
    "\n",
    "# using matplotlib to plot\n",
    "# creates a new figure\n",
    "plt.plot(time, signal, 'b')\n",
    "# title of the plot\n",
    "plt.title(\"Sound Wave\")\n",
    "\n",
    "# label of x-axis\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Soundwave\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.plot(time1, signal1, 'r')\n",
    "\n",
    "# title of the plot\n",
    "plt.title(\"Sound Wave\")\n",
    "\n",
    "# label of x-axis\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Soundwave\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = os.path.join(absolute_path, \"Ketquathuam\")\n",
    "t1 = os.path.join(t1, \"Son\")\n",
    "t1 = os.path.join(t1, \"KH-CN\")\n",
    "t1 = os.path.join(t1, \"KH-CN03.wav\")\n",
    "print(calc_distances(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_set = calc_distances(t1)\n",
    "\n",
    "my_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# end = 0\n",
    "\n",
    "# if accept_test(pattern, t1, min_error):\n",
    "#     min_val = 10000\n",
    "\n",
    "#     fs, data = read(t1)\n",
    "#     data_size = len(data)\n",
    "\n",
    "#     # The number of indexes on 0.15 seconds\n",
    "#     focus_size = int(0.15 * fs)\n",
    "\n",
    "#     focuses = []\n",
    "#     distances = []\n",
    "#     idx = 0\n",
    "\n",
    "#     while idx < len(data):\n",
    "#         if data[idx] > min_val:\n",
    "#             mean_idx = idx + focus_size // 2\n",
    "#             focuses.append(float(mean_idx) / data_size)\n",
    "#             if len(focuses) > 1:\n",
    "#                 last_focus = focuses[-2]\n",
    "#                 actual_focus = focuses[-1]\n",
    "#                 distances.append(actual_focus - last_focus)\n",
    "#                 start = start * 1000 #Works in milliseconds\n",
    "#                 end = \n",
    "#                 end = end * 1000\n",
    "#                 newAudio = AudioSegment.from_wav(t1)\n",
    "#                 newAudio = newAudio[start:end]\n",
    "#                 newAudio.export('newSong.wav', format=\"wav\")\n",
    "#             idx += focus_size\n",
    "#         else:\n",
    "#             idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = input_data1\n",
    "source = input_data\n",
    "\n",
    "# read the sample to look for\n",
    "rate_snippet, snippet = wavfile.read(snippet)\n",
    "\n",
    "snippet = snippet.reshape(-1, 1)\n",
    "snippet = np.array(snippet[:,0], dtype='float')\n",
    "\n",
    "# read the source\n",
    "rate, source = wavfile.read(source)\n",
    "\n",
    "source = source.reshape(-1, 1)\n",
    "source = np.array(source[:,0], dtype='float')\n",
    "\n",
    "# resample such that both signals are at the same sampling rate (if required)\n",
    "if rate != rate_snippet:\n",
    "    num = int(np.round(rate*len(snippet)/rate_snippet))\n",
    "    snippet = signal.resample(snippet, num) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_snippet = np.arange(0, snippet.size) / rate_snippet # type: ignore\n",
    "plt.plot(x_snippet, snippet)\n",
    "plt.xlabel('seconds')\n",
    "plt.title('snippet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_source = np.arange(0, source.size) / rate# type: ignore\n",
    "figure(figsize=(20, 6), dpi=80)\n",
    "plt.plot(x_source, source)\n",
    "plt.xlabel('seconds')\n",
    "plt.title('source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cross-correlation\n",
    "z = signal.correlate(source, snippet, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.size == z.size # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_z = np.arange(0, z.size) / rate\n",
    "plt.plot(x_z, z)   # type: ignore\n",
    "plt.axhline(1.25e10, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = signal.find_peaks(\n",
    "    z,\n",
    "    height=1.25e10,\n",
    "    distance=50000\n",
    ")\n",
    "peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_idxs = peaks[0]\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "plt.plot(x_z, z)\n",
    "plt.plot(x_z[peaks_idxs], z[peaks_idxs], 'or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "plt.plot(x_source, source)\n",
    "plt.xlabel('seconds')\n",
    "plt.title('source signal and correlatation')\n",
    "for i, peak_idx in enumerate(peaks_idxs):\n",
    "    start = (peak_idx-snippet.size/2) / rate #type: ignore\n",
    "    center = (peak_idx) / rate\n",
    "    end   = (peak_idx+snippet.size/2) / rate #type: ignore\n",
    "    plt.axvline(start,  color='g')\n",
    "    plt.axvline(center, color='y')\n",
    "    plt.axvline(end,    color='r')\n",
    "    print(f\"peak {i}: start {start:.2f} end {end:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "input_data = f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\"\n",
    "input_data1 = f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\"\n",
    "\n",
    "def split_audio_by_pattern(original_file, pattern_file):\n",
    "    original = AudioSegment.from_wav(original_file)\n",
    "    pattern = AudioSegment.from_wav(pattern_file)\n",
    "    chunk_duration = len(pattern)\n",
    "    chunks = original[::chunk_duration]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.export(f\"{absolute_path}/dataset/Son/KH-CN/processed/split_{i}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = f\"{absolute_path}/pattern/AnhSon/reduce-noise/test0.wav\"\n",
    "source = input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snippet, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = f\"{absolute_path}/pattern/AnhSon/reduce-noise/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_segment.export(f\"{absolute_path}/dataset/Son/KH-CN/processed/pro{i}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_audio  = f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\"\n",
    "original_audio  = f\"{absolute_path}/Ketquathuam/AnhSon/KH-CN/KH-CN03.wav\"\n",
    "print(original_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_audios = []\n",
    "\n",
    "for c, f in enumerate(os.listdir(snippet)):\n",
    "    pattern_audios.append(f\"{absolute_path}/pattern/AnhSon/reduce-noise/{f}\")\n",
    "\n",
    "pattern_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# from fastdtw import fastdtw  #type: ignore\n",
    "# import os\n",
    "\n",
    "# def dtw_distance(x, y):\n",
    "#     distance, _ = fastdtw(x, y, dist=lambda x, y: abs(x-y))\n",
    "#     return distance\n",
    "\n",
    "# def audio_segmentation(audio_file, pattern_files, segment_length=5.0, distance_threshold=10.0):\n",
    "#     audio, sr = librosa.load(audio_file, sr=None)\n",
    "#     audio_length = librosa.get_duration(audio, sr=sr)\n",
    "#     n_segments = int(audio_length / segment_length)\n",
    "#     sub_audio_files = []\n",
    "#     start = 0\n",
    "#     patterns = []\n",
    "#     for pattern_file in pattern_files:\n",
    "#         pattern, _ = librosa.load(pattern_file, sr=sr)\n",
    "#         patterns.append(pattern)\n",
    "#     for i in range(n_segments):\n",
    "#         end = start + segment_length\n",
    "#         start_idx = int(start * sr)\n",
    "#         end_idx = int(end * sr)\n",
    "#         segment = audio[start_idx:end_idx]\n",
    "#         min_distance = np.inf\n",
    "#         nearest_pattern = None\n",
    "#         for pattern in patterns:\n",
    "#             distance = dtw_distance(segment, pattern)\n",
    "#             if distance < min_distance:\n",
    "#                 min_distance = distance\n",
    "#                 nearest_pattern = pattern\n",
    "#         if min_distance < distance_threshold:\n",
    "#             sub_audio = audio[start_idx:end_idx]\n",
    "#             librosa.output.write_wav(f'{absolute_path}/dataset/Son/KH-CN/processed/file{i}.wav', sub_audio, sr) #type: ignore\n",
    "#             sub_audio_files.append(sub_audio)\n",
    "#         start = end\n",
    "#     return sub_audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import soundfile as sf\n",
    "\n",
    "# def audio_segmentation(audio_file, pattern_files, distance_threshold, max_chunk_size=10, chunk_overlap=5):\n",
    "#     # Load the original audio\n",
    "#     original_audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "#     # Load all the pattern audio files\n",
    "#     pattern_audios = [librosa.load(f)[0] for f in pattern_files]\n",
    "    \n",
    "#     # Calculate the cosine similarity between the original audio and all the pattern audios\n",
    "#     distance = np.array([librosa.metrics.pairwise.cosine_similarity(original_audio.reshape(1, -1), pa.reshape(1, -1)) for pa in pattern_audios])\n",
    "    \n",
    "#     # Find the pattern with the highest similarity to the original audio\n",
    "#     best_pattern_index = np.argmax(distance)\n",
    "#     best_pattern = pattern_audios[best_pattern_index]\n",
    "    \n",
    "#     # Determine the start and end time of the best pattern in the original audio\n",
    "#     start, end = librosa.core.cross_correlate(original_audio, best_pattern)\n",
    "    \n",
    "#     # Extract the segment of the original audio that matches the best pattern\n",
    "#     sub_audio = original_audio[start:end]\n",
    "    \n",
    "#     # Save the extracted segment to a new audio file\n",
    "#     sf.write(f\"{absolute_path}/Ketquathuam/file{}\", sub_audio, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "def audio_segmentation(audio_file, pattern_files):\n",
    "    original_audio, sr = librosa.load(audio_file)\n",
    "    pattern_audios = [librosa.load(f, sr=sr)[0] for f in pattern_files]\n",
    "    \n",
    "    starts = []\n",
    "    ends = []\n",
    "    distances = []\n",
    "    for i, pattern_audio in enumerate(pattern_audios):\n",
    "        distance = librosa.sequence.dtw(original_audio, pattern_audio, subseq=True)[0]\n",
    "        starts.append(np.argmin(distance))\n",
    "        ends.append(starts[-1]+len(pattern_audio))\n",
    "        distances.append(np.min(distance))\n",
    "    \n",
    "    starts = np.array(starts)\n",
    "    ends = np.array(ends)\n",
    "    distances = np.array(distances)\n",
    "    sort_idx = np.argsort(starts)\n",
    "    starts = starts[sort_idx]\n",
    "    ends = ends[sort_idx]\n",
    "    distances = distances[sort_idx]\n",
    "    pattern_files = [pattern_files[i] for i in sort_idx]\n",
    "    \n",
    "    sub_audios = []\n",
    "    for i in range(len(starts)):\n",
    "        if i == 0:\n",
    "            sub_audio = original_audio[:starts[i]]\n",
    "        else:\n",
    "            sub_audio = original_audio[ends[i-1]:starts[i]]\n",
    "        sf.write(f\"{absolute_path}/Ketquathuam/result{i}.wav\", sub_audio, sr)\n",
    "    sub_audio = original_audio[ends[-1]:]\n",
    "    sub_audios.append(sub_audio)\n",
    "    sub_audio_filename = os.path.join(output_folder, f'{len(starts)}_end.wav')\n",
    "    sf.write(sub_audio_filename, sub_audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{absolute_path}/Ketquathuam/AnhSon/KH-CN/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_segmentation(original_audio, pattern_audios, f'{absolute_path}/dataset/Son/KH-CN/processed/')\n",
    "audio_segmentation(original_audio, pattern_audios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
