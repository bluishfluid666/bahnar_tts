{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "import wave\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_path = os.path.dirname(\n",
    "    \"/Users/khangnguyen/lab/bahnar_tts/\")\n",
    "# absolute_path = os.path.dirname(\n",
    "#     \"E:/SOFT/General_Subjects/artificial_intelligence/colab-tts-Bahnar/bahnar_tts/\")\n",
    "relative_path = \"pattern\"\n",
    "\n",
    "fullpath = os.path.join(absolute_path, relative_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChiBi\n",
      ".DS_Store\n",
      "AnhSon\n"
     ]
    }
   ],
   "source": [
    "for count, filename in enumerate(os.listdir(fullpath)):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distances(sound_file):\n",
    "    min_val = 10000\n",
    "\n",
    "    fs, data = read(sound_file)\n",
    "    data_size = len(data)\n",
    "\n",
    "    focus_size = int(0.15 * fs)\n",
    "\n",
    "    focuses = []\n",
    "    distances = []\n",
    "    idx = 0\n",
    "\n",
    "    while idx < len(data):\n",
    "        if data[idx] > min_val:\n",
    "            mean_idx = idx + focus_size // 2\n",
    "            focuses.append(float(mean_idx) / data_size)\n",
    "            if len(focuses) > 1:\n",
    "                last_focus = focuses[-2]\n",
    "                actual_focus = focuses[-1]\n",
    "                distances.append(actual_focus - last_focus)\n",
    "            idx += focus_size\n",
    "        else:\n",
    "            idx += 1\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_test(pattern, test, min_error):\n",
    "    if len(pattern) > len(test):\n",
    "        return False\n",
    "    for i, dt in enumerate(pattern):\n",
    "        if not dt - test[i] < min_error:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for count, filename in enumerate(os.listdir(fullpath)):\n",
    "    if filename == \"AnhSon\" or filename == \"ChiBi\":\n",
    "        subpath = os.path.join(fullpath, filename)\n",
    "        for c, f in enumerate(os.listdir(subpath)):\n",
    "            if f == \"conv-wav\":\n",
    "                subsubpath = os.path.join(subpath, f)\n",
    "                for c1, f1 in enumerate(os.listdir(subsubpath)):\n",
    "                    audiopath = os.path.join(subsubpath, f1)\n",
    "\n",
    "                    print(audiopath)\n",
    "                    raw = wave.open(audiopath)\n",
    "\n",
    "                    # reads all the frames\n",
    "                    # -1 indicates all or max frames\n",
    "                    signal = raw.readframes(-1)\n",
    "                    signal = np.frombuffer(signal, dtype=\"int16\")\n",
    "\n",
    "                    # gets the frame rate\n",
    "                    f_rate = raw.getframerate()\n",
    "\n",
    "                    time = np.linspace(\n",
    "                        0,  # start\n",
    "                        len(signal) / f_rate,\n",
    "                        num=len(signal)\n",
    "                    )\n",
    "                    print(len(signal))\n",
    "\n",
    "                    # using matplotlib to plot\n",
    "                    # creates a new figure\n",
    "                    plt.plot(time, signal, 'b')\n",
    "\n",
    "                    # load data\n",
    "                    r, d = wavfile.read(f\"{audiopath}\")\n",
    "                    # perform noise reduction\n",
    "                    reduced_noise = nr.reduce_noise(y=d, sr=r)\n",
    "                    wavfile.write(\n",
    "                        f\"{subpath}/reduce-noise/test{c1}.wav\", r, reduced_noise)\n",
    "\n",
    "                    # do a comparison of the reduced noise files\n",
    "                    adjusted_filepath = os.path.join(subpath, \"reduce-noise\")\n",
    "                    adjusted_filepath = os.path.join(\n",
    "                        adjusted_filepath, f\"test{c1}.wav\")\n",
    "\n",
    "                    raw = wave.open(adjusted_filepath)\n",
    "\n",
    "                    # reads all the frames\n",
    "                    # -1 indicates all or max frames\n",
    "                    signal = raw.readframes(-1)\n",
    "                    signal = np.frombuffer(signal, dtype=\"int16\")\n",
    "\n",
    "                    # gets the frame rate\n",
    "                    f_rate = raw.getframerate()\n",
    "\n",
    "\n",
    "                    # using matplotlib to plot\n",
    "                    # creates a new figure\n",
    "                    plt.plot(time, signal, 'r')\n",
    "\n",
    "                    # shows the plot\n",
    "                    # in new window\n",
    "                    plt.show()\n",
    "\n",
    "                    # title of the plot\n",
    "                    plt.title(\"Sound Wave\")\n",
    "\n",
    "                    # label of x-axis\n",
    "                    plt.xlabel(\"Time\")\n",
    "                    plt.ylabel(\"Soundwave\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, filename in enumerate(os.listdir(fullpath)):\n",
    "    if filename == \"AnhSon\":\n",
    "        subpath = os.path.join(fullpath, filename)\n",
    "        for c, f in enumerate(os.listdir(subpath)):\n",
    "            if f == \"reduce-noise\":\n",
    "                subsubpath = os.path.join(subpath, f)\n",
    "                for c1, f1 in enumerate(os.listdir(subsubpath)):\n",
    "                    if f1.endswith('wav'):\n",
    "                        audiopath = os.path.join(subsubpath, f1)\n",
    "                        print(audiopath)\n",
    "                        fs, data = read(audiopath)\n",
    "                        # we will use the size of the array\n",
    "                        # to determine the duration of the sound\n",
    "                        data_size = len(data)\n",
    "\n",
    "                        # build k-nearest neighbors\n",
    "                        # ...\n",
    "\n",
    "                        pattern = calc_distances(f1)\n",
    "                        test = calc_distances()  # filename to be processed #type: ignore\n",
    "\n",
    "                        min_error = 0.1\n",
    "\n",
    "                        print(accept_test(pattern, test, min_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = calc_distances(f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\")\n",
    "test = calc_distances(f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = f\"{absolute_path}/Ketquathuam/AnhSon/KH-CN/KH-CN03.wav\"\n",
    "input_data1 = f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\"\n",
    "# input_data = f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\"\n",
    "# input_data1 = f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\"\n",
    "\n",
    "raw = wave.open(input_data)\n",
    "raw1 = wave.open(input_data1)\n",
    "\n",
    "signal = raw.readframes(-1)\n",
    "signal = np.frombuffer(signal, dtype=\"int16\")\n",
    "signal1 = raw1.readframes(-1)\n",
    "signal1 = np.frombuffer(signal1, dtype=\"int16\")\n",
    "\n",
    "# gets the frame rate\n",
    "f_rate = raw.getframerate()\n",
    "f_rate1 = raw1.getframerate()\n",
    "\n",
    "time = np.linspace(\n",
    "    0,  # start\n",
    "    len(signal) / f_rate,\n",
    "    num=len(signal)\n",
    ")\n",
    "time1 = np.linspace(\n",
    "    0,  # start\n",
    "    len(signal1) / f_rate1,\n",
    "    num=len(signal1)\n",
    ")\n",
    "\n",
    "# using matplotlib to plot\n",
    "# creates a new figure\n",
    "plt.plot(time, signal, 'b')\n",
    "# title of the plot\n",
    "plt.title(\"Sound Wave\")\n",
    "\n",
    "# label of x-axis\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Soundwave\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.plot(time1, signal1, 'r')\n",
    "\n",
    "# title of the plot\n",
    "plt.title(\"Sound Wave\")\n",
    "\n",
    "# label of x-axis\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Soundwave\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = os.path.join(absolute_path, \"Ketquathuam\")\n",
    "t1 = os.path.join(t1, \"Son\")\n",
    "t1 = os.path.join(t1, \"KH-CN\")\n",
    "t1 = os.path.join(t1, \"KH-CN03.wav\")\n",
    "print(calc_distances(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_set = calc_distances(t1)\n",
    "\n",
    "my_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# end = 0\n",
    "\n",
    "# if accept_test(pattern, t1, min_error):\n",
    "#     min_val = 10000\n",
    "\n",
    "#     fs, data = read(t1)\n",
    "#     data_size = len(data)\n",
    "\n",
    "#     # The number of indexes on 0.15 seconds\n",
    "#     focus_size = int(0.15 * fs)\n",
    "\n",
    "#     focuses = []\n",
    "#     distances = []\n",
    "#     idx = 0\n",
    "\n",
    "#     while idx < len(data):\n",
    "#         if data[idx] > min_val:\n",
    "#             mean_idx = idx + focus_size // 2\n",
    "#             focuses.append(float(mean_idx) / data_size)\n",
    "#             if len(focuses) > 1:\n",
    "#                 last_focus = focuses[-2]\n",
    "#                 actual_focus = focuses[-1]\n",
    "#                 distances.append(actual_focus - last_focus)\n",
    "#                 start = start * 1000 #Works in milliseconds\n",
    "#                 end = \n",
    "#                 end = end * 1000\n",
    "#                 newAudio = AudioSegment.from_wav(t1)\n",
    "#                 newAudio = newAudio[start:end]\n",
    "#                 newAudio.export('newSong.wav', format=\"wav\")\n",
    "#             idx += focus_size\n",
    "#         else:\n",
    "#             idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = input_data1\n",
    "source = input_data\n",
    "\n",
    "# read the sample to look for\n",
    "rate_snippet, snippet = wavfile.read(snippet)\n",
    "\n",
    "snippet = snippet.reshape(-1, 1)\n",
    "snippet = np.array(snippet[:,0], dtype='float')\n",
    "\n",
    "# read the source\n",
    "rate, source = wavfile.read(source)\n",
    "\n",
    "source = source.reshape(-1, 1)\n",
    "source = np.array(source[:,0], dtype='float')\n",
    "\n",
    "# resample such that both signals are at the same sampling rate (if required)\n",
    "if rate != rate_snippet:\n",
    "    num = int(np.round(rate*len(snippet)/rate_snippet))\n",
    "    snippet = signal.resample(snippet, num) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_snippet = np.arange(0, snippet.size) / rate_snippet # type: ignore\n",
    "plt.plot(x_snippet, snippet)\n",
    "plt.xlabel('seconds')\n",
    "plt.title('snippet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_source = np.arange(0, source.size) / rate# type: ignore\n",
    "figure(figsize=(20, 6), dpi=80)\n",
    "plt.plot(x_source, source)\n",
    "plt.xlabel('seconds')\n",
    "plt.title('source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cross-correlation\n",
    "z = signal.correlate(source, snippet, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.size == z.size # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_z = np.arange(0, z.size) / rate\n",
    "plt.plot(x_z, z)   # type: ignore\n",
    "plt.axhline(1.25e10, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = signal.find_peaks(\n",
    "    z,\n",
    "    height=1.25e10,\n",
    "    distance=50000\n",
    ")\n",
    "peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_idxs = peaks[0]\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "plt.plot(x_z, z)\n",
    "plt.plot(x_z[peaks_idxs], z[peaks_idxs], 'or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "plt.plot(x_source, source)\n",
    "plt.xlabel('seconds')\n",
    "plt.title('source signal and correlatation')\n",
    "for i, peak_idx in enumerate(peaks_idxs):\n",
    "    start = (peak_idx-snippet.size/2) / rate #type: ignore\n",
    "    center = (peak_idx) / rate\n",
    "    end   = (peak_idx+snippet.size/2) / rate #type: ignore\n",
    "    plt.axvline(start,  color='g')\n",
    "    plt.axvline(center, color='y')\n",
    "    plt.axvline(end,    color='r')\n",
    "    print(f\"peak {i}: start {start:.2f} end {end:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "input_data = f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\"\n",
    "input_data1 = f\"{absolute_path}/pattern/AnhSon/conv-wav/test.wav\"\n",
    "\n",
    "def split_audio_by_pattern(original_file, pattern_file):\n",
    "    original = AudioSegment.from_wav(original_file)\n",
    "    pattern = AudioSegment.from_wav(pattern_file)\n",
    "    chunk_duration = len(pattern)\n",
    "    chunks = original[::chunk_duration]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.export(f\"{absolute_path}/dataset/Son/KH-CN/processed/split_{i}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = f\"{absolute_path}/pattern/AnhSon/reduce-noise/test0.wav\"\n",
    "source = input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test0.wav /Users/khangnguyen/lab/bahnar_tts/dataset/Son/KH-CN/KH-CN03.wav\n"
     ]
    }
   ],
   "source": [
    "print(snippet, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = f\"{absolute_path}/pattern/AnhSon/reduce-noise/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_segment.export(f\"{absolute_path}/dataset/Son/KH-CN/processed/pro{i}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/khangnguyen/lab/bahnar_tts/Ketquathuam/AnhSon/KH-CN/KH-CN03.wav\n"
     ]
    }
   ],
   "source": [
    "# original_audio  = f\"{absolute_path}/dataset/Son/KH-CN/KH-CN03.wav\"\n",
    "original_audio  = f\"{absolute_path}/Ketquathuam/AnhSon/KH-CN/KH-CN03.wav\"\n",
    "print(original_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test4.wav',\n",
       " '/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test5.wav',\n",
       " '/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test7.wav',\n",
       " '/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test6.wav',\n",
       " '/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test2.wav',\n",
       " '/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test3.wav',\n",
       " '/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test1.wav',\n",
       " '/Users/khangnguyen/lab/bahnar_tts/pattern/AnhSon/reduce-noise/test0.wav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_audios = []\n",
    "\n",
    "for c, f in enumerate(os.listdir(snippet)):\n",
    "    pattern_audios.append(f\"{absolute_path}/pattern/AnhSon/reduce-noise/{f}\")\n",
    "\n",
    "pattern_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# from fastdtw import fastdtw  #type: ignore\n",
    "# import os\n",
    "\n",
    "# def dtw_distance(x, y):\n",
    "#     distance, _ = fastdtw(x, y, dist=lambda x, y: abs(x-y))\n",
    "#     return distance\n",
    "\n",
    "# def audio_segmentation(audio_file, pattern_files, segment_length=5.0, distance_threshold=10.0):\n",
    "#     audio, sr = librosa.load(audio_file, sr=None)\n",
    "#     audio_length = librosa.get_duration(audio, sr=sr)\n",
    "#     n_segments = int(audio_length / segment_length)\n",
    "#     sub_audio_files = []\n",
    "#     start = 0\n",
    "#     patterns = []\n",
    "#     for pattern_file in pattern_files:\n",
    "#         pattern, _ = librosa.load(pattern_file, sr=sr)\n",
    "#         patterns.append(pattern)\n",
    "#     for i in range(n_segments):\n",
    "#         end = start + segment_length\n",
    "#         start_idx = int(start * sr)\n",
    "#         end_idx = int(end * sr)\n",
    "#         segment = audio[start_idx:end_idx]\n",
    "#         min_distance = np.inf\n",
    "#         nearest_pattern = None\n",
    "#         for pattern in patterns:\n",
    "#             distance = dtw_distance(segment, pattern)\n",
    "#             if distance < min_distance:\n",
    "#                 min_distance = distance\n",
    "#                 nearest_pattern = pattern\n",
    "#         if min_distance < distance_threshold:\n",
    "#             sub_audio = audio[start_idx:end_idx]\n",
    "#             librosa.output.write_wav(f'{absolute_path}/dataset/Son/KH-CN/processed/file{i}.wav', sub_audio, sr) #type: ignore\n",
    "#             sub_audio_files.append(sub_audio)\n",
    "#         start = end\n",
    "#     return sub_audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = f'{absolute_path}/dataset/Son/KH-CS/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def audio_segmentation(original_audio_file, pattern_files, distance_threshold=0.5, max_chunk_size=1, chunk_overlap=0.5):\n",
    "    original_audio, sr = librosa.load(original_audio_file)\n",
    "    chunk_starts = librosa.effects.split(original_audio, top_db=30, frame_length=max_chunk_size*sr, hop_length=int(chunk_overlap*sr))\n",
    "    chunk_ends = chunk_starts[1:] + [len(original_audio)]\n",
    "    for i in range(len(chunk_starts)):\n",
    "        print(chunk_starts[i])\n",
    "#         chunk = original_audio[int(chunk_starts[i][0]):int(chunk_ends[i][1])]\n",
    "#         distances = []\n",
    "#         for pattern_file in pattern_files:\n",
    "#             pattern, _ = librosa.load(pattern_file, sr=sr)\n",
    "#             if chunk.shape[0] < pattern.shape[0]:\n",
    "#                 distances.append(np.inf)\n",
    "#                 continue\n",
    "#             distances.append(librosa.feature.mfcc(y=chunk, sr=sr, n_mfcc=13).shape[1] - librosa.feature.mfcc(y=pattern, sr=sr, n_mfcc=13).shape[1])\n",
    "#         if np.min(np.abs(distances)) < distance_threshold:\n",
    "#             sub_audio = chunk\n",
    "#             librosa.output.write_wav(f\"{output_folder}/file{i}.wav\", sub_audio, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 0 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maudio_segmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_audio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern_audios\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m, in \u001b[0;36maudio_segmentation\u001b[0;34m(original_audio_file, pattern_files, distance_threshold, max_chunk_size, chunk_overlap)\u001b[0m\n\u001b[1;32m      7\u001b[0m     chunk_ends \u001b[38;5;241m=\u001b[39m chunk_starts[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mlen\u001b[39m(original_audio)]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(chunk_starts)):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#         print(chunk_starts[i])\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m original_audio[\u001b[38;5;28mint\u001b[39m(chunk_starts[i][\u001b[38;5;241m0\u001b[39m]):\u001b[38;5;28mint\u001b[39m(\u001b[43mchunk_ends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     11\u001b[0m         distances \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m pattern_file \u001b[38;5;129;01min\u001b[39;00m pattern_files:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 0 with size 8"
     ]
    }
   ],
   "source": [
    "audio_segmentation(original_audio, pattern_audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
